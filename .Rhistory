train <- df_norm[subset1, ]
test <- df_norm[-subset1, ]
# Set up labels for train/test sets
train_labels <- df[subset1, 1]
test_labels <- df[-subset1, 1]
# Define k for model
k <- round(sqrt(nrow(df)), 0)
library(class)
cbb_knn <- knn(train = train,
test = test,
cl = train_labels,
k = k)
library(gmodels)
CrossTable(x = test_labels,
y = cbb_knn,
prop.chisq = F)
# 69% accuracy with the model. Try to improve by varying k
library(e1071)
str(train)
knntuning <- tune.knn(x = train,
y = train_labels,
k=1:10)
knntuning
summary(knntuning)
# Define k for model
k <- round(sqrt(nrow(df)), 0)
knntuning <- tune.knn(x = train,
y = train_labels,
k = 150:200)
knntuning
summary(knntuning)
summary(knntuning)[2]
knntuning$best.performance[2]
summary(knntuning)
plot(summary(knntuning))
class(summary(knntuning))
knntuning <- tune.knn(x = train,
y = train_labels,
k = 50:100)
seq(0, 100, by = 10)
seq(10, 200, by = 10)
k <- seq(10, 200, by = 10)
str(train)
knntuning <- tune.knn(x = train,
y = train_labels,
k = k)
knntuning
summary(knntuning)
df <- data_AdjE
# Normalize data before building model
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
df_norm <- lapply(df[,-1], normalize) %>%
as.data.frame()
# Convert Home_w into a factor
df$Home_w <- factor(df$Home_w, levels = c(0,1), labels = c('Home_loss', 'Home_win'))
head(df)
# Split into train/test data
subset1 <- sample(nrow(df_norm), size = 0.8*nrow(df))
train <- df_norm[subset1, ]
test <- df_norm[-subset1, ]
# Set up labels for train/test sets
train_labels <- df[subset1, 1]
test_labels <- df[-subset1, 1]
# Define k for model
k <- round(sqrt(nrow(df)), 0)
library(class)
cbb_knn <- knn(train = train,
test = test,
cl = train_labels,
k = k)
library(gmodels)
CrossTable(x = test_labels,
y = cbb_knn,
prop.chisq = F)
library(caret)
confusionMatrix(test_labels,
cbb_knn)
# 69% accuracy with the model. Try to improve by varying k
library(e1071)
k <- seq(10, 200, by = 10)
str(train)
knntuning <- tune.knn(x = train,
y = train_labels,
k = k)
knntuning
summary(knntuning)
1-.279
df <- data_barthag
# Normalize data before building model
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
df_norm <- lapply(df[,-1], normalize) %>%
as.data.frame()
# Convert Home_w into a factor
df$Home_w <- factor(df$Home_w, levels = c(0,1), labels = c('Home_loss', 'Home_win'))
head(df)
# Split into train/test data
subset1 <- sample(nrow(df_norm), size = 0.8*nrow(df))
train <- df_norm[subset1, ]
test <- df_norm[-subset1, ]
# Set up labels for train/test sets
train_labels <- df[subset1, 1]
test_labels <- df[-subset1, 1]
# Define k for model
k <- round(sqrt(nrow(df)), 0)
library(class)
cbb_knn <- knn(train = train,
test = test,
cl = train_labels,
k = k)
library(caret)
confusionMatrix(test_labels,
cbb_knn)
# Split into train/test data
subset1 <- sample(nrow(df_norm), size = 0.8*nrow(df))
train <- df_norm[subset1, ]
test <- df_norm[-subset1, ]
# Set up labels for train/test sets
train_labels <- df[subset1, 1]
test_labels <- df[-subset1, 1]
# Define k for model
k <- round(sqrt(nrow(df)), 0)
library(class)
cbb_knn <- knn(train = train,
test = test,
cl = train_labels,
k = k)
library(caret)
confusionMatrix(test_labels,
cbb_knn)
# 69% accuracy with the model. Try to improve by varying k
library(e1071)
k <- seq(10, 200, by = 10)
str(train)
knntuning <- tune.knn(x = train,
y = train_labels,
k = k)
knntuning
knntuning
summary(knntuning)
# Build new model with optimal value of k (170)
cbb_knn <- knn(train = train,
test = test,
cl = train_labels,
k = 170)
# Check accuracy using a confusion matrix
confusionMatrix(tbi.test.labels,
tbi_knn)
# Check accuracy using a confusion matrix
confusionMatrix(test_labels,
cbb_knn)
model_data$pred_Home_w <- predict(cbb_knn,
newdata = model_data)
class(cbb_knn)
cbb_knn
# Check accuracy using a confusion matrix
confusionMatrix(test_labels,
cbb_knn)
# Test model on 2019 season games
season <- read.csv(here('data/season_data2019.csv'))
season <- dplyr::filter(season, as.Date(Date) > as.Date('2018-11-20'))
head(season)
df <- data_AdjE
# Normalize data before building model
normalize <- function(x){
return((x-min(x))/(max(x)-min(x)))
}
df_norm <- lapply(df[,-1], normalize) %>%
as.data.frame()
# Convert Home_w into a factor
df$Home_w <- factor(df$Home_w, levels = c(0,1), labels = c('Home_loss', 'Home_win'))
head(df)
# Split into train/test data
subset1 <- sample(nrow(df_norm), size = 0.8*nrow(df))
train <- df_norm[subset1, ]
test <- df_norm[-subset1, ]
# Set up labels for train/test sets
train_labels <- df[subset1, 1]
test_labels <- df[-subset1, 1]
# Define k for model
k <- round(sqrt(nrow(df)), 0)
library(class)
cbb_knn <- knn(train = train,
test = test,
cl = train_labels,
k = k)
library(caret)
confusionMatrix(test_labels,
cbb_knn)
# 69% accuracy with the model. Try to improve by varying k
library(e1071)
k <- seq(10, 200, by = 10)
str(train)
knntuning <- tune.knn(x = train,
y = train_labels,
k = k)
knntuning
summary(knntuning)
# Build new model with optimal value of k (170)
cbb_knn <- knn(train = train,
test = test,
cl = train_labels,
k = 160)
# Check accuracy using a confusion matrix
confusionMatrix(test_labels,
cbb_knn)
# Test model on 2019 season games
season <- read.csv(here('data/season_data2019.csv'))
season$Home_w_factor <- factor(season$Home_w,
levels = c(0,1),
labels = c('Home_loss', 'Home_win'))
View(season)
# Normalize AdjE columns
season1 <- select(season, Home_w_factor, Date)
# Normalize AdjE columns
season1 <- select(season, Home_w_factor, AdjE_off_road, AdjE_off_home,
AdjE_def_road, AdjE_def_home)
View(season1)
# Normalize AdjE columns
season1 <- select(season, Home_w_factor, AdjE_off_road, AdjE_off_home,
AdjE_def_road, AdjE_def_home) %>%
.[complete.cases(.), ]
View(season1)
# Normalize AdjE columns
season1[,2:5] <- lapply(season1[,2:5], normalize) %>%
as.data.frame()
View(season1)
season$pred_Home_w <- knn(train = train,
test = season1[,2:5],
cl = season1[,1],
k = 160)
season$pred_Home_w <- knn(train = train,
test = season1[,2:5],
cl = train_labels,
k = 160)
preds <- knn(train = train,
test = season1[,2:5],
cl = train_labels,
k = 160)
length(preds)
preds
season$pred_Home_w_factor <- preds
season1$pred_Home_w_factor <- preds
season1$pred_Home_w <- knn(train = train,
test = season1[,2:5],
cl = train_labels,
k = 160)
# Test model on 2019 season games
season <- read.csv(here('data/season_data2019.csv'))
season$Home_w_factor <- factor(season$Home_w,
levels = c(0,1),
labels = c('Home_loss', 'Home_win'))
# Select AdjE columns
season1 <- select(season, Home_w_factor, AdjE_off_road, AdjE_off_home,
AdjE_def_road, AdjE_def_home) %>%
.[complete.cases(.), ]
# Normalize AdjE columns
season1[,2:5] <- lapply(season1[,2:5], normalize) %>%
as.data.frame()
season1$pred_Home_w <- knn(train = train,
test = season1[,2:5],
cl = train_labels,
k = 160)
table(season1$pred_Home_w == season1$Home_w_factor)
prop.table(table(season1$pred_Home_w == season1$Home_w_factor))
# Select AdjE columns
season1 <- select(season, Home_w_factor, AdjE_off_road, AdjE_off_home,
AdjE_def_road, AdjE_def_home) %>%
.[complete.cases(.), ]
# Normalize AdjE columns
season1[,2:5] <- lapply(season1[,2:5], normalize) %>%
as.data.frame()
season1$pred_Home_w <- knn(train = train,
test = season1[,2:5],
cl = train_labels,
k = 180)
prop.table(table(season1$pred_Home_w == season1$Home_w_factor))
# Use all previous games as training set
train <- df_norm
train_labels <- df[, 1]
# Check accuracy for 2019 season
season1$pred_Home_w <- knn(train = train,
test = season1[,2:5],
cl = train_labels,
k = 180)
prop.table(table(season1$pred_Home_w == season1$Home_w_factor))
# Run model on upcoming games and check season accuracy
library(here)
library(dplyr)
# Update games and torvik data (only use if updating last 2 days)
source(here('src/update_data_master.R'))
fit1 <- readRDS(here('models/log_regression_adje_model.rds'))
# Test model on 2019 season games
season <- read.csv(here('data/season_data2019.csv'))
season$pred <- predict(fit1, newdata = season,
type = 'response') #%>%
season$pred_Home_w <- round(season$pred,0)
season$pred_correct <- ifelse(season$pred_Home_w == season$Home_w, 1, 0)
# Check accuracy for yesterday, last week, last month
check_accuracy <- function(n_days){
x <- filter(season, as.Date(Date) < Sys.Date()) %>%
filter(as.Date(Date) >= Sys.Date()-n_days) %>%
select(pred_correct) %>%
table()
names(x) <- c('Incorrect', 'Correct')
print(paste('Last',n_days,'days:',
100*round(prop.table(x)[2], 3),
'percent accuracy'))
x
}
# Check accuracy for 2019 season
check_accuracy(300)
check_accuracy(1)
check_accuracy(7)
check_accuracy(30)
check_accuracy(60)
# Chart of running model accuracy
season1 <- season[complete.cases(season), ] %>%
filter(as.Date(Date) < Sys.Date())
season1$games <- 1:nrow(season1)
season1$running_accuracy <- cumsum(season1$pred_correct)/season1$games
library(ggplot2)
ggplot(aes(y = running_accuracy, x = as.Date(Date)),
data = season1)+
geom_line(lwd = .8, col = 'red')+
ylab('Running Model Accuracy')+
xlab('Date')+
ggtitle('2019 NCAA basketball predictive model accuracy')
# Predictions for todays games
# Predict winner using logistic regression model
todays_games <- filter(season, as.Date(Date) == Sys.Date())
todays_games$pred <- predict(fit1,
newdata = todays_games,
type = 'response') %>%
round(., 4)
# Predict margin and total using linear regression models
fit_margin <- readRDS(here('models/lin_regression_adje_model_margin.rds'))
fit_total <- readRDS(here('models/lin_regression_adje_model_total.rds'))
todays_games$pred_margin <- predict(fit_margin,
newdata = todays_games,
type = 'response') %>%
round()
todays_games$pred_total <- predict(fit_total,
newdata = todays_games,
type = 'response') %>%
round()
# Convert margin and total into predicted Home/Road scores
todays_games$pred_Home <- round(todays_games$pred_total/2 - todays_games$pred_margin/2, 0)
todays_games$pred_Road <- round(todays_games$pred_total/2 + todays_games$pred_margin/2, 0)
todays_games <- todays_games[,c(7,1,2,49:55)] %>%
mutate(pred_winner = ifelse(pred >= 0.5,
as.character(Home),
as.character(Road)),
confidence = abs(pred - 0.5) + 0.5) %>%
select(c('Date', 'Road', 'pred_Road', 'Home', 'pred_Home',
'pred_winner', 'confidence', 'pred_margin',
'pred_total'))
dir.create(here('results/'))
write.csv(todays_games, file = here('results/todays_games_predictions.csv'), row.names = F)
# Upload as a google sheet to google drive
library(googlesheets)
gs_upload(file = here('results/todays_games_predictions.csv'), overwrite = T)
# Save and upload season stats to google drive
write.csv(season1,
file = here('results/2019_season_completed.csv'),
row.names = F)
gs_upload(file = here('results/2019_season_completed.csv'), overwrite = T)
View(todays_games)
# Run model on upcoming games and check season accuracy
library(here)
library(dplyr)
# Update games and torvik data (only use if updating last 2 days)
source(here('src/update_data_master.R'))
fit1 <- readRDS(here('models/log_regression_adje_model.rds'))
# Test model on 2019 season games
season <- read.csv(here('data/season_data2019.csv'))
season$pred <- predict(fit1, newdata = season,
type = 'response') #%>%
season$pred_Home_w <- round(season$pred,0)
season$pred_correct <- ifelse(season$pred_Home_w == season$Home_w, 1, 0)
# Check accuracy for yesterday, last week, last month
check_accuracy <- function(n_days){
x <- filter(season, as.Date(Date) < Sys.Date()) %>%
filter(as.Date(Date) >= Sys.Date()-n_days) %>%
select(pred_correct) %>%
table()
names(x) <- c('Incorrect', 'Correct')
print(paste('Last',n_days,'days:',
100*round(prop.table(x)[2], 3),
'percent accuracy'))
x
}
# Check accuracy for 2019 season
check_accuracy(300)
check_accuracy(1)
check_accuracy(7)
check_accuracy(30)
check_accuracy(60)
# Predictions for todays games
# Predict winner using logistic regression model
todays_games <- filter(season, as.Date(Date) == Sys.Date())
todays_games$pred <- predict(fit1,
newdata = todays_games,
type = 'response') %>%
round(., 4)
# Predict margin and total using linear regression models
fit_margin <- readRDS(here('models/lin_regression_adje_model_margin.rds'))
fit_total <- readRDS(here('models/lin_regression_adje_model_total.rds'))
todays_games$pred_margin <- predict(fit_margin,
newdata = todays_games,
type = 'response') %>%
round()
todays_games$pred_total <- predict(fit_total,
newdata = todays_games,
type = 'response') %>%
round()
# Convert margin and total into predicted Home/Road scores
todays_games$pred_Home <- round(todays_games$pred_total/2 - todays_games$pred_margin/2, 0)
todays_games$pred_Road <- round(todays_games$pred_total/2 + todays_games$pred_margin/2, 0)
todays_games <- todays_games[,c(7,1,2,49:55)] %>%
mutate(pred_winner = ifelse(pred >= 0.5,
as.character(Home),
as.character(Road)),
confidence = abs(pred - 0.5) + 0.5) %>%
select(c('Date', 'Road', 'pred_Road', 'Home', 'pred_Home',
'pred_winner', 'confidence', 'pred_margin',
'pred_total'))
dir.create(here('results/'))
write.csv(todays_games, file = here('results/todays_games_predictions.csv'), row.names = F)
# Upload as a google sheet to google drive
library(googlesheets)
gs_upload(file = here('results/todays_games_predictions.csv'), overwrite = T)
# Save and upload season stats to google drive
write.csv(season1,
file = here('results/2019_season_completed.csv'),
row.names = F)
gs_upload(file = here('results/2019_season_completed.csv'), overwrite = T)
# Run model on upcoming games and check season accuracy
library(here)
library(dplyr)
# Update games and torvik data (only use if updating last 2 days)
source(here('src/update_data_master.R'))
fit1 <- readRDS(here('models/log_regression_adje_model.rds'))
# Test model on 2019 season games
season <- read.csv(here('data/season_data2019.csv'))
season$pred <- predict(fit1, newdata = season,
type = 'response') #%>%
season$pred_Home_w <- round(season$pred,0)
season$pred_correct <- ifelse(season$pred_Home_w == season$Home_w, 1, 0)
# Check accuracy for yesterday, last week, last month
check_accuracy <- function(n_days){
x <- filter(season, as.Date(Date) < Sys.Date()) %>%
filter(as.Date(Date) >= Sys.Date()-n_days) %>%
select(pred_correct) %>%
table()
names(x) <- c('Incorrect', 'Correct')
print(paste('Last',n_days,'days:',
100*round(prop.table(x)[2], 3),
'percent accuracy'))
x
}
# Check accuracy for 2019 season
check_accuracy(300)
check_accuracy(1)
check_accuracy(7)
check_accuracy(30)
check_accuracy(60)
# Chart of running model accuracy
season1 <- season[complete.cases(season), ] %>%
filter(as.Date(Date) < Sys.Date())
# Predictions for todays games
# Predict winner using logistic regression model
todays_games <- filter(season, as.Date(Date) == Sys.Date())
todays_games$pred <- predict(fit1,
newdata = todays_games,
type = 'response') %>%
round(., 4)
# Predict margin and total using linear regression models
fit_margin <- readRDS(here('models/lin_regression_adje_model_margin.rds'))
fit_total <- readRDS(here('models/lin_regression_adje_model_total.rds'))
todays_games$pred_margin <- predict(fit_margin,
newdata = todays_games,
type = 'response') %>%
round()
todays_games$pred_total <- predict(fit_total,
newdata = todays_games,
type = 'response') %>%
round()
# Convert margin and total into predicted Home/Road scores
todays_games$pred_Home <- round(todays_games$pred_total/2 - todays_games$pred_margin/2, 0)
todays_games$pred_Road <- round(todays_games$pred_total/2 + todays_games$pred_margin/2, 0)
todays_games <- todays_games[,c(7,1,2,49:55)] %>%
mutate(pred_winner = ifelse(pred >= 0.5,
as.character(Home),
as.character(Road)),
confidence = abs(pred - 0.5) + 0.5) %>%
select(c('Date', 'Road', 'pred_Road', 'Home', 'pred_Home',
'pred_winner', 'confidence', 'pred_margin',
'pred_total'))
dir.create(here('results/'))
write.csv(todays_games, file = here('results/todays_games_predictions.csv'), row.names = F)
# Upload as a google sheet to google drive
library(googlesheets)
gs_upload(file = here('results/todays_games_predictions.csv'), overwrite = T)
# Save and upload season stats to google drive
write.csv(season1,
file = here('results/2019_season_completed.csv'),
row.names = F)
gs_upload(file = here('results/2019_season_completed.csv'), overwrite = T)
